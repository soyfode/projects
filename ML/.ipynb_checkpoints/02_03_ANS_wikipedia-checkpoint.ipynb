{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c05ca9d-ef18-43c6-a60e-13b43bde4d97",
   "metadata": {},
   "source": [
    "# Wikipedia\n",
    "\n",
    "## Una matriz de frecuencia de palabras tf-idf\n",
    "Empezaremos creando una matriz de frecuencia de palabras `tf-idf` para una colección de documentos. Para ello, utilice el `TfidfVectorizer`. Transforma una lista de documentos en una matriz de frecuencias de palabras, cuya salida es una matriz `csr_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf269d-a3a4-40bc-9aeb-8fab71cb7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un TfidfVectorizer: tfidf\n",
    "# tfidf = TfidfVectorizer() \n",
    "\n",
    "# Aplicar fit_transform al documento: csr_mat\n",
    "# csr_mat = tfidf.fit_transform(documents)\n",
    "\n",
    "# Imprimir el resultado del método toarray()\n",
    "# print(csr_mat.toarray())\n",
    "\n",
    "# Obtener las palabras: words\n",
    "# words = tfidf.get_feature_names()\n",
    "\n",
    "# Imprimir palabras\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f892ff6-698e-474e-a9c9-2afe8dc6c69a",
   "metadata": {},
   "source": [
    "## Agrupación de Wikipedia parte I \n",
    "\n",
    "Recordemos que `TruncatedSVD` puede realizar PCA en matrices dispersas en formato `csr_matrix`, como matrices de frecuencia de palabras. \n",
    "\n",
    "Combinemos `TruncatedSVD` y `k-means` para agrupar algunas páginas populares de Wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a5c1d300-5c99-4880-b1de-13647f83c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRERIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6270706a-83cb-4faa-8ca2-af993eacf037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "(60, 13125)\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "ruta_archivo = '/home/jovyan/notebooks/data/wikipedia-vectors.csv'\n",
    "articles = pd.read_csv(ruta_archivo,index_col = 0)\n",
    "titles = articles.columns.tolist()\n",
    "articles = articles.values\n",
    "articles = articles.T\n",
    "print(len(titles))\n",
    "print(articles.shape)\n",
    "ruta_archivo = '/home/jovyan/notebooks/data/wikipedia-vocabulary-utf8.txt'\n",
    "with open(ruta_archivo, 'r') as archivo:\n",
    "    # Lee las líneas del archivo\n",
    "    words = [linea.strip() for linea in archivo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e19fd6f6-cb24-4153-82d4-9be45032c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia TruncatedSVD: svd\n",
    "svd = TruncatedSVD(n_components = 50)\n",
    "\n",
    "# Crear una instancia KMeans: kmeans\n",
    "kmeans = KMeans(n_clusters = 6, n_init = 10)\n",
    "\n",
    "# Crear un pipeline: pipeline\n",
    "pipeline = make_pipeline(svd, kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd97b16-f2b8-43c0-a523-c6287f5b764e",
   "metadata": {},
   "source": [
    "## Wikipedia en clústeres, parte II\n",
    "\n",
    "\n",
    "Recordemos que tenemos una matriz de artículos de tf-idf palabra-frecuencia de algunos artículos populares de Wikipedia, y una lista de títulos `titles. Utilizaremos el pipeline para agrupar los artículos de Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a41d5599-ad57-47bd-a0ef-4af03ae1bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label                                        article\n",
      "14      0                                 Climate change\n",
      "19      0  2007 United Nations Climate Change Conference\n",
      "18      0  2010 United Nations Climate Change Conference\n",
      "17      0  Greenhouse gas emissions by the United States\n",
      "16      0                                        350.org\n",
      "15      0                                 Kyoto Protocol\n",
      "13      0                               Connie Hedegaard\n",
      "12      0                                   Nigel Lawson\n",
      "11      0       Nationally Appropriate Mitigation Action\n",
      "10      0                                 Global warming\n",
      "59      1                                    Adam Levine\n",
      "50      1                                   Chad Kroeger\n",
      "57      1                          Red Hot Chili Peppers\n",
      "56      1                                       Skrillex\n",
      "55      1                                  Black Sabbath\n",
      "54      1                                 Arctic Monkeys\n",
      "58      1                                         Sepsis\n",
      "52      1                                     The Wanted\n",
      "51      1                                     Nate Ruess\n",
      "53      1                                   Stevie Nicks\n",
      "30      2                  France national football team\n",
      "39      2                                  Franck Ribéry\n",
      "37      2                                       Football\n",
      "36      2              2014 FIFA World Cup qualification\n",
      "35      2                Colombia national football team\n",
      "34      2                             Zlatan Ibrahimović\n",
      "33      2                                 Radamel Falcao\n",
      "32      2                                   Arsenal F.C.\n",
      "31      2                              Cristiano Ronaldo\n",
      "38      2                                         Neymar\n",
      "29      3                               Jennifer Aniston\n",
      "27      3                                 Dakota Fanning\n",
      "26      3                                     Mila Kunis\n",
      "25      3                                  Russell Crowe\n",
      "24      3                                   Jessica Biel\n",
      "23      3                           Catherine Zeta-Jones\n",
      "22      3                              Denzel Washington\n",
      "21      3                             Michael Fassbender\n",
      "20      3                                 Angelina Jolie\n",
      "28      3                                  Anne Hathaway\n",
      "49      4                                       Lymphoma\n",
      "48      4                                     Gabapentin\n",
      "47      4                                          Fever\n",
      "46      4                                     Prednisone\n",
      "45      4                                    Hepatitis C\n",
      "43      4                                       Leukemia\n",
      "42      4                                    Doxycycline\n",
      "41      4                                    Hepatitis B\n",
      "40      4                                    Tonsillitis\n",
      "44      4                                           Gout\n",
      "9       5                                       LinkedIn\n",
      "8       5                                        Firefox\n",
      "7       5                                  Social search\n",
      "6       5                    Hypertext Transfer Protocol\n",
      "5       5                                         Tumblr\n",
      "4       5                                  Google Search\n",
      "3       5                                    HTTP cookie\n",
      "2       5                              Internet Explorer\n",
      "1       5                                 Alexa Internet\n",
      "0       5                                       HTTP 404\n"
     ]
    }
   ],
   "source": [
    "# Ajustar el pipeline a los artículos\n",
    "pipeline.fit(articles)\n",
    "\n",
    "# Predecir las etiquetas de los clusters: labels\n",
    "labels = pipeline.predict(articles)\n",
    "\n",
    "# Crear un DataFrame alineando las etiquetas y los títulos: df\n",
    "df = pd.DataFrame({'label': labels, 'article': titles})\n",
    "\n",
    "# Mostrar df ordenado por la etiqueta del cluster\n",
    "print(df.sort_values('label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a30e3-bc0d-4bc2-9426-5cc2d904c4da",
   "metadata": {},
   "source": [
    "## NMF aplicado a artículos de Wikipedia\n",
    "\n",
    "Ajustaremos el modelo y transforma los artículos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4d56ff6-383e-4ffb-9d1a-2bef2ace106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.44]\n",
      " [0.   0.   0.   0.   0.   0.56]\n",
      " [0.   0.   0.   0.   0.   0.4 ]\n",
      " [0.   0.   0.   0.   0.   0.38]\n",
      " [0.   0.   0.   0.   0.   0.48]\n",
      " [0.01 0.01 0.01 0.03 0.   0.33]\n",
      " [0.   0.   0.02 0.   0.01 0.36]\n",
      " [0.   0.   0.   0.   0.   0.49]\n",
      " [0.02 0.01 0.   0.02 0.03 0.48]\n",
      " [0.01 0.03 0.03 0.07 0.02 0.34]\n",
      " [0.   0.   0.53 0.   0.03 0.  ]\n",
      " [0.   0.   0.35 0.   0.   0.  ]\n",
      " [0.01 0.01 0.31 0.06 0.01 0.02]\n",
      " [0.   0.01 0.34 0.01 0.   0.  ]\n",
      " [0.   0.   0.43 0.   0.04 0.  ]\n",
      " [0.   0.   0.48 0.   0.   0.  ]\n",
      " [0.01 0.02 0.37 0.03 0.   0.01]\n",
      " [0.   0.   0.48 0.   0.   0.  ]\n",
      " [0.   0.01 0.55 0.   0.   0.  ]\n",
      " [0.   0.   0.46 0.   0.   0.  ]\n",
      " [0.   0.01 0.02 0.51 0.06 0.01]\n",
      " [0.   0.   0.   0.51 0.   0.  ]\n",
      " [0.   0.01 0.   0.42 0.   0.  ]\n",
      " [0.   0.   0.   0.43 0.   0.  ]\n",
      " [0.   0.   0.   0.49 0.   0.  ]\n",
      " [0.1  0.09 0.   0.38 0.   0.01]\n",
      " [0.   0.   0.   0.57 0.   0.01]\n",
      " [0.01 0.01 0.   0.47 0.   0.01]\n",
      " [0.   0.   0.   0.57 0.   0.  ]\n",
      " [0.   0.   0.   0.52 0.01 0.01]\n",
      " [0.   0.41 0.   0.   0.   0.  ]\n",
      " [0.   0.6  0.   0.01 0.   0.  ]\n",
      " [0.01 0.26 0.   0.02 0.01 0.  ]\n",
      " [0.   0.64 0.   0.   0.   0.  ]\n",
      " [0.   0.61 0.   0.   0.   0.  ]\n",
      " [0.   0.34 0.   0.   0.   0.  ]\n",
      " [0.01 0.31 0.02 0.   0.01 0.  ]\n",
      " [0.01 0.21 0.01 0.05 0.02 0.01]\n",
      " [0.01 0.46 0.   0.02 0.   0.  ]\n",
      " [0.   0.64 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.47 0.  ]\n",
      " [0.   0.   0.   0.   0.49 0.  ]\n",
      " [0.   0.   0.   0.   0.38 0.01]\n",
      " [0.   0.   0.   0.01 0.54 0.  ]\n",
      " [0.   0.   0.01 0.   0.42 0.  ]\n",
      " [0.   0.   0.   0.   0.51 0.  ]\n",
      " [0.   0.   0.   0.   0.37 0.  ]\n",
      " [0.   0.   0.04 0.   0.23 0.  ]\n",
      " [0.01 0.   0.02 0.01 0.32 0.04]\n",
      " [0.   0.   0.   0.   0.42 0.  ]\n",
      " [0.3  0.   0.   0.   0.   0.  ]\n",
      " [0.36 0.   0.   0.   0.   0.  ]\n",
      " [0.39 0.03 0.   0.02 0.   0.02]\n",
      " [0.37 0.   0.   0.04 0.   0.01]\n",
      " [0.43 0.   0.   0.   0.   0.  ]\n",
      " [0.45 0.   0.   0.   0.   0.  ]\n",
      " [0.27 0.   0.   0.05 0.   0.02]\n",
      " [0.44 0.   0.   0.   0.01 0.  ]\n",
      " [0.29 0.01 0.01 0.01 0.19 0.01]\n",
      " [0.37 0.01 0.   0.1  0.01 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia de NMF: model\n",
    "model = NMF(n_components = 6)\n",
    "\n",
    "# Ajustar el modelo a los artículos\n",
    "model.fit(articles)\n",
    "\n",
    "# Transformar los artículos: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Imprimir las características de NMF\n",
    "print(nmf_features.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c0e04-b620-4c20-a3a4-00f21cfcc937",
   "metadata": {},
   "source": [
    "## Características NMF de los artículos de Wikipedia\n",
    "\n",
    "Ahora exploraremos las características NMF que creamos.\n",
    "\n",
    "Al investigar las características, observemos que para ambos actores, la característica 3 NMF tiene con diferencia el valor más alto. Esto significa que ambos artículos se reconstruyen utilizando principalmente el componente 3 del NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61010fc7-58ec-405f-a444-f82dbcc1ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.003815\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "3    0.571957\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "Name: Anne Hathaway, dtype: float64\n",
      "0    0.000000\n",
      "1    0.005575\n",
      "2    0.000000\n",
      "3    0.419630\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "Name: Denzel Washington, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame de pandas: df\n",
    "df = pd.DataFrame(nmf_features, index = titles)\n",
    "\n",
    "# Imprimir la fila para 'Anne Hathaway'\n",
    "print(df.loc[\"Anne Hathaway\"])\n",
    "\n",
    "# Imprimir la fila para 'Denzel Washington'\n",
    "print(df.loc[\"Denzel Washington\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fdc0bb-c106-4933-af85-8de7071d4dd2",
   "metadata": {},
   "source": [
    "## El NMF aprende los temas de los documentos\n",
    "\n",
    "Cuando se aplica NMF a documentos, los componentes corresponden a temas de documentos, y las características NMF reconstruyen los documentos a partir de los temas. Comprobaremos esto con el modelo NMF que construimos anteriormente utilizando los artículos de Wikipedia. \n",
    "\n",
    "Anteriormente, viste que el valor de la tercera característica NMF era alto para los artículos sobre los actores Anne Hathaway y Denzel Washington. Acá identificaremos el tema del componente NMF correspondiente.\n",
    "\n",
    "El modelo NMF que construyó anteriormente está disponible como modelo, mientras que palabras es una lista de las palabras que etiquetan las columnas de la matriz de frecuencia de palabras.\n",
    "\n",
    "Cuando hayas terminado, tómate un momento para reconocer el tema que tienen en común los artículos sobre Anne Hathaway y Denzel Washington."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "192e4d53-9431-4e08-8ff8-7a3ddbc2a922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 13125)\n",
      "film       0.632005\n",
      "award      0.254794\n",
      "starred    0.246897\n",
      "role       0.212841\n",
      "actress    0.187623\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame components_df a partir de model.components_, \n",
    "# estableciendo columns=words para que las columnas estén etiquetadas \n",
    "# por las palabras.\n",
    "components_df = pd.DataFrame(model.components_, columns = words)\n",
    "\n",
    "# Imprimir la forma del DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Seleccionar la fila 3: component\n",
    "component = components_df.iloc[3]\n",
    "\n",
    "# Llamar al método .nlargest() e imprima el resultado. \n",
    "## Esto da las cinco palabras con los valores más altos \n",
    "## para ese componente.\n",
    "print(component.nlargest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4437ab-81f3-47b9-bcc0-cef8d4f5035c",
   "metadata": {},
   "source": [
    "## ¿Qué artículos son similares a \"Cristiano Ronaldo\"?\n",
    "Ahora, encontraremos los artículos más similares al artículo sobre el futbolista Cristiano Ronaldo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b44d6d9b-7257-4f4d-a8d4-09d3b8c03f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo                1.000000\n",
      "Franck Ribéry                    0.999973\n",
      "Radamel Falcao                   0.999942\n",
      "Zlatan Ibrahimović               0.999942\n",
      "France national football team    0.999923\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalizar las características de NMF: norm_features\n",
    "norm_features = normalize(nmf_features)\n",
    "\n",
    "# Crear un DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index = titles)\n",
    "\n",
    "# Seleccionar la fila correspondiente a 'Cristiano Ronaldo': article\n",
    "article = df.loc['Cristiano Ronaldo']\n",
    "\n",
    "# Calcular los productos punto: similarities\n",
    "similarities = df.dot(article)\n",
    "\n",
    "# Mostrar aquellos con la mayor similitud del coseno\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37223a4-2bb5-4e09-aa35-c2ad388d88bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
