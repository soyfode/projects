{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f464b2f-269d-4742-87cd-611801d290c1",
   "metadata": {},
   "source": [
    "# Clasificadores lineales\n",
    "\n",
    "## Aplicando la regresión logística y SVM\n",
    "\n",
    "Empecemos recordando algunos pasos típicos de aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e1668c9-1556-4b4c-a10e-196b42b8898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEBRERIA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb468c33-f694-47da-8b1e-2f947e196fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de los grupos de noticias del repositorio \n",
    "# de conjunto de datos integrados en scikit-learn\n",
    "newsgroups = sklearn.datasets.fetch_20newsgroups_vectorized()\n",
    "X, y = newsgroups.data, newsgroups.target\n",
    "\n",
    "# Inspeccionar la forma de X e y.\n",
    "print(X.shape)\n",
    "print()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060eb3d1-d014-4c7a-a393-79eaf4367e26",
   "metadata": {},
   "source": [
    "-  En este caso las características se derivan de las palabras que aparencen en cada articulo de noticia y los valores son los temas del artículo que es lo que intentamos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d9498-73ab-4b6c-b48f-6c1a537f295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intanciar KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "# Ajustar el modelo con el conjunto de datos\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Precedir \n",
    "y_pred = knn.predict(X)\n",
    "\n",
    "is_alive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb493d-65f4-44ee-a351-16edc796c890",
   "metadata": {},
   "source": [
    "### Evaluando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891f923-760e-466b-81e0-6609d52a705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar .score() para evaluar el modelo\n",
    "knn.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80601b-2a62-4c10-8003-e78a7744612f",
   "metadata": {},
   "source": [
    "- El número no es particularmente significativo, ya que queremos saber cómo se generaliza el modelo a datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866eedb-9d5f-4989-9a10-b9add9034b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Volver a ajustar al conjunto de datos\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Calcular la puntación de la prueba\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0c01d-0460-4a01-aa1b-eb7c6cc7d781",
   "metadata": {},
   "source": [
    "### Ejecutar regresión lineal y SVM\n",
    "\n",
    "Pongamos cómo ejemplo el conjunto de datos de vino de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f74a35-413f-4cd1-bf0a-186796a4339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el cojunto de datos\n",
    "wine = sklearn.datasets.load_wine()\n",
    "\n",
    "# Instanciar el clasificador\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Ajustar el clasificador al conjunto de datos \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "lr.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del entrenamiento\n",
    "lr.score(wine.data, wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e550e-97e5-47e9-b748-28af3f14a4f9",
   "metadata": {},
   "source": [
    "- `LogicticRegression()` puede también generar puntajes de confianza en lugar de predicciones \"duras\" y definitivas\n",
    "- Esto se realiza con `predic_proba()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d45429-f1c5-4ae6-b746-38ec7203e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el puntaje de confianza\n",
    "lr.prodict_proba(wine.data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661001b1-5eae-4961-940f-187c7d1158ed",
   "metadata": {},
   "source": [
    "#### Usando el clasificador SVM\n",
    "\n",
    "- Usaremos `LinearSVC()` que funciona de la misma manera que `LogisticRegression()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4aea1d-6292-4ed7-8a0b-70ddec033911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el cojunto de datos\n",
    "wine = sklearn.datasets.load_wine()\n",
    "\n",
    "# Instanciar SVM\n",
    "svm = LinearSVC()\n",
    "\n",
    "# Ajustar a los datos\n",
    "smv.fit(wine.data, wine.target)\n",
    "\n",
    "# calcular la precisión \n",
    "smv.score(wine.data, wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b079970-b5d9-4c41-b1f3-4b1db6a854eb",
   "metadata": {},
   "source": [
    "#### Usando la clase SVC\n",
    "\n",
    "- Se ajusta a una SVM no lineal por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359bbf56-60b2-4563-bd36-b11923edc26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar SVC\n",
    "svm = SVC()\n",
    "\n",
    "# Ajustar a los datos\n",
    "smv.fit(wine.data, wine.target)\n",
    "\n",
    "# calcular la precisión \n",
    "smv.score(wine.data, wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d166e-746d-45e7-9019-854cebfc1b4f",
   "metadata": {},
   "source": [
    "- Con los hiperparámetros predeterminados, la precisión no es particularmente alta, pero es posible que al ajustar los hiperparámetros de este model lleguemos a una precisión del 100%.\n",
    "- Pero tal clasificador podría estar sobreajustado, lo cual es un riesgo que corremos cuando usamos modelos más complejos como `SVM` *no lineales*.\n",
    "- Un ***hiperparámetro*** es una elección sobre el modelo que haces antes de ajustar a los datos, y a menudo contrala la complejidad del modelo.\n",
    "    - Si el modelo es muy simple, es posible que no pueda capturar los patrones en los datos, lo que lleva a una baja precisión del entrenamiento o **Desajuste**.\n",
    "    - Si el modelo es demasiado complejo, puede aprender las peculiaridades de su conjunto de entrenamiento particular, lo que lleva a una mejor precisión con los datos de prueba o **Sobreajuste**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3beb274-2f85-438b-944e-356e5f453206",
   "metadata": {},
   "source": [
    "### Clasificadores lineales\n",
    "\n",
    "Discutiremos lo que significa que un clasificador sea lineal\n",
    "- Comencemos hablando del **límite de decisión**\n",
    "    - Nos dice qué clase predecirá nuestro clasificador para cualquier valor de $X$. En otras palabras, es ***la linea que parte a dos regiones.***\n",
    "    - Esta linea no tiene porque ser horizontal, puede estar en cualquier orientación.\n",
    "    - Esta definición se extiende a más de 2 características también. Lo que sería un **hiperplano** de dimensión superior que corta el espacio en dos mitadas\n",
    "- Un límite no lineal es cualquier otro tipo de límite.\n",
    "- En sus formas básicas, la regresión logística y las SVM son clasificadores que aprenden de límites de decisión lineal.\n",
    "\n",
    "**DEFINICIONES**\n",
    "- *Clasificación:* Es aprendizaje supervisado cuando los valores de $y$ son categóricos, ya que está en contraste con la regresión, donde estamos tratando de predecir un valor continuo.\n",
    "- *Límites de decisión:* Superficie que separa en diferentes clases. \n",
    "- *Clasificadores lineales:* Un clasificador que aprende de los límites de decisión lineales.\n",
    "- *Linealmente separable:* Es un conjunto de datos si puede ser perfectamente explicado por un clasificador lineal.\n",
    "\n",
    "#### Visualización de los límites de decisión\n",
    "\n",
    "Visualizaremos los límites de decisión de varios tipos de clasificadores en el conjunto de datos `wine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82210ae-e503-4a32-9de2-12541754a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los clasificadores\n",
    "classifiers = [LogisticRegression(), LinearSVC(), SVC(), KNeighborsClassifier()]\n",
    "\n",
    "# Entrenar los clasificadores\n",
    "for c in classifiers:\n",
    "    c.fit(X, y)\n",
    "\n",
    "# Graficar los clasificadores\n",
    "plot_4_classifiers(X, y, classifiers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa72c3-b12a-4a6f-b5d5-28f735c95dc1",
   "metadata": {},
   "source": [
    "## Funciones de pérdida (loss functions)\n",
    "\n",
    "### Clasificadores lineales: los coeficientes\n",
    "\n",
    "#### Producto escalar\n",
    "- Empecemos creando un *array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a124483-f0ad-408f-909d-b64bdc51e8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array x\n",
    "x = np.arange(3)\n",
    "\n",
    "# Array y\n",
    "y = np.arange(3,6)\n",
    "\n",
    "# Multiplicamos x e y\n",
    "x*y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277dce90-f8a5-404b-803b-6de6b9892266",
   "metadata": {},
   "source": [
    "- El resultado es 0 (0 por 3), 4 (de 1 por 4) y 10 (de 2 por 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1d938c-d657-46fe-bc71-91ffabd41fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x*y)\n",
    "\n",
    "# o\n",
    "x@y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e9bce-e42c-4d62-baa0-8e1ecf97bf85",
   "metadata": {},
   "source": [
    "- La suma de estos número, también conocida como **producto escalar** es 14\n",
    "$$x\\cdot y$$\n",
    "\n",
    "#### Predicción del clasificador lineal\n",
    "\n",
    "- Usando productos escalares, podemos expresar cómo los clasificadores lineales hacen predicciones.\n",
    "    1. Calculamos lo que llamaremos **resultado del modelo sin procesar** que es el producto escalar de los coeficientes y las características mas una intersección.\n",
    "      $$\\text{Salida del modelo sin procesar} = \\text{Coeficientes}\\cdot \\text{características} + \\text{intercepto}$$\n",
    "    2. Luego tomamos el signo de esta cantidad. Es decir, comprobamos si es positivo o negativo.\n",
    "- Fundamentalmente, ***este patrón es el mismo tanto para la regresión logística como para las SVM lineales.***\n",
    "- En `scikit-learn` la regresión logística y las SVM tiene diferentes funciones de ajuste pero la misma función de predicción.\n",
    "- Las diferencias en el \"ajuste\" se relacionan con la funciones de pérdida.\n",
    "\n",
    "Veamos la ecuación:\n",
    "  $$\\text{Salida del modelo sin procesar} = \\text{Coeficientes}\\cdot \\text{características} + \\text{intercepto}$$\n",
    "en acción con el conjunto de datos de clasificación de cáncer de mama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2845e28d-1419-431d-9830-814e9bba8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Cargar el cojunto de datos\n",
    "X, y = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "# Crear un objeto de regresión logística\n",
    "lr = LogisticRegression(max_iter = 3361)\n",
    "\n",
    "# Ajustar a los datos\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predecir en lo ejemplos 10 y 20\n",
    "print(lr.predict(X)[20])\n",
    "print(lr.predict(X)[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cd0c4-a72a-48f8-917c-949a3eacbdb6",
   "metadata": {},
   "source": [
    "- Analicemos a profundidad. Podemos obtener los coeficientes aprendidos e interceptarlos con `lr.coef_` y `lr[10]`.\n",
    "    - Calculemos la salida del modelo sin procesar para el ejemplo 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8763676e-ca7e-4b31-9223-d8f2f2dbdcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.06636689])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salida del modelo 10 sin procesar\n",
    "lr.coef_ @ X[10] + lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf79fcf-370d-48b2-9907-cce8c20e7892",
   "metadata": {},
   "source": [
    "- Dado que es negativo, predecimos la clases negativa, llamada \"0\" en este conjunto de datos.\n",
    "\n",
    "-  Para el ejemplo 20 la salida del modelo sin procesar es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfd53d20-7abf-4a9f-95c9-84f582d4873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.24316423])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salida del modelo para 20 sin procesar\n",
    "lr.coef_ @ X[20] + lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df1040-aad0-4b03-9223-5d42cb6e6a61",
   "metadata": {},
   "source": [
    "- Dado que es positivo, predecimos la otra clase, llamada \"1\" en este conjunto de datos.\n",
    "- En general, esto es lo que hace la función de predicción para cualquier X, calcula la salida del modelo sin procesar, verifica si es posiivo o negatico y luego regresa un resultado basado en los nombres de las clases en su conjunto de datos, en este caso 0 y 1.\n",
    "- En resumen, el signo, positivo o negativo, te dice de qué lado del límite de decisión esta \"y\".\n",
    "- Además, los valores de los coeficientes y la intersección determinan el límite. Para cambiar la orientación del límite, podemos cambiar los coeficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5f3fd-a3de-4776-b107-25476f9726f2",
   "metadata": {},
   "source": [
    "#### Cambio de los coeficientes del modelo\n",
    "\n",
    "Cuando se llama a ajustar con scikit-learn, los coeficientes de regresión logística se aprenden automáticamente de su conjunto de datos. Exploraremos cómo el límite de decisión está representado por los coeficientes. Para ello, cambiará los coeficientes manualmente (en lugar de con fit), y visualizará los clasificadores resultantes.\n",
    "\n",
    "Crearemos un conjunto de datos 2D como X e y, junto con un modelo de objeto clasificador lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8099e32a-8e1f-4f95-8fbb-e948a576ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de errores: 212\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[ 1.78862847,  0.43650985],\n",
    "       [ 0.09649747, -1.8634927 ],\n",
    "       [-0.2773882 , -0.35475898],\n",
    "       [-3.08274148,  2.37299932],\n",
    "       [-3.04381817,  2.52278197],\n",
    "       [-1.31386475,  0.88462238],\n",
    "       [-2.11868196,  4.70957306],\n",
    "       [-2.94996636,  2.59532259],\n",
    "       [-3.54535995,  1.45352268],\n",
    "       [ 0.98236743, -1.10106763],\n",
    "       [-1.18504653, -0.2056499 ],\n",
    "       [-1.51385164,  3.23671627],\n",
    "       [-4.02378514,  2.2870068 ],\n",
    "       [ 0.62524497, -0.16051336],\n",
    "       [-3.76883635,  2.76996928],\n",
    "       [ 0.74505627,  1.97611078],\n",
    "       [-1.24412333, -0.62641691],\n",
    "       [-0.80376609, -2.41908317],\n",
    "       [-0.92379202, -1.02387576],\n",
    "       [ 1.12397796, -0.13191423]])\n",
    "y = np.array([-1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1,  1,  1, -1,  1, -1, -1,\n",
    "       -1, -1, -1])\n",
    "\n",
    "# Cargar el cojunto de datos\n",
    "X, y = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "# Crear un objeto de regresión logística\n",
    "lr = LogisticRegression(max_iter = 3361)\n",
    "\n",
    "# Ajustar a los datos\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Establecer los coeficientes\n",
    "lr.coef_ = np.array([np.ones(30)])\n",
    "lr.intercept_ = np.array([-3])\n",
    "\n",
    "# Graficar los datos y la frontera de decisión\n",
    "# plot_classifier(X,y,lr)\n",
    "\n",
    "# Imprimir el número de errores\n",
    "num_err = np.sum(y != lr.predict(X))\n",
    "print(\"Número de errores:\", num_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a155e-1925-4bf8-af27-ab1fc2b27089",
   "metadata": {},
   "source": [
    "### ¿Qué es la función de pérdida?\n",
    "\n",
    "- Muchos algoritmos de aprendije automático implican minimizar una pérdida. Por ejemplo, la reresión lineal de mínimos cuadrados.\n",
    "- ***Puede pensar en minimizar la pérdida como mover los coeficientes o parámetros del modelo hasta que este término de error, o función de pérdida, sea lo más pequeño posible.***\n",
    "- En otras palabras, la función de pérdida es una puntuación de penalización que nos dice cómo bien (o que tan mal) está funcionando el modelo con los datos de entrenamiento.\n",
    "- Podemos pensar en la función de \"ajuste\" como código en ejecución que minimiza la pérdida.\n",
    "- Tenga en cuenta que `.score()` de scikit-learn no es necesariamente la misma que la función de pérdida.\n",
    "- La pérdida se usa para ajustar el modelo a los datos y la puntuación `score()` se usa para ver que tan bien lo estamos haciendo.\n",
    "- El error cuatrático de `LinearRegression()` no es apropiado para problemas de clasificación, ya que nuestros valores de $y$ son categorías, no número.\n",
    "- Para ***la clasificación, una cantidad natural en la que pensar es la cantidad de errores que hemos cometido.*** Dado que nos gustaría que esto fuera lo más pequeño posible, la cantidad de errores podría ser una buena función de pérdida.\n",
    "- Nos referimos a esta función como la pérdida 0-1, porque está definida para 0 (prediccion correcta) o 1 (predicción incorrecta).\n",
    "- Al sumar esta función sobre todos los ejemplos de entrrenamiento, obtenemos el número de errores que hemos cometido en el conjunto de entrenamient, ya que sumamos 1 al total por cada error. Pero resulta ser muy difícil para minimizar directamente en la práctica. Razón por la cual la regresión logística y SVM no la usan.\n",
    "- Para minimizar todo tipo de funciones utilizaremos `from scipy.optimize import minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7830b3d1-ae3d-4c47-a347-429dcafb56a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimizar x^2\n",
    "minimize(np.square, 0).x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de4a7f0-8394-4a7d-bb07-216df2de7918",
   "metadata": {},
   "source": [
    "- Intentemos otra suposición inicial para ver si realmente está haciendo algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f5c76ce-d5da-464a-bcf1-feef94f69ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.88846401e-08])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimizar x^2\n",
    "minimize(np.square, 2).x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d695c9-d03b-4ce0-b076-32b27a4bd50d",
   "metadata": {},
   "source": [
    "- En el contexto de la regresión nos preguntaremos \n",
    "**¿Qué valores de los coeficientes del modelo hacen que mi error cuadrático sea lo más pequeño posible?**\n",
    "\n",
    "### Diagramas de función de pérdida\n",
    "\n",
    "- Supongamos que queremos dibujar funciones de pérdida, así que configuremos un gráfico con pérdida en el eje vertical.\n",
    "- En el eje horizontal trazaremos la salida del modelo sin procesar.\n",
    "    - La mitad izquierda predecimos una clase (-1) y en la mitad derecha predecimos la otra clase (+1).\n",
    "    - Osea, la mitad izquierda representa predicciónes correctas y la mitad izquierda representa predicciones incorrectas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adb80798-2b0f-49b4-957f-4c9a11edb3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297acb4-3729-41bd-9e1d-83b0653a1998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
