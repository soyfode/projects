{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09162033-c5b2-438f-bc30-b51d0531984a",
   "metadata": {},
   "source": [
    "# Machine learning con modelos basados en árboles\n",
    "\n",
    "## Clasificación y árboles de regresión\n",
    "\n",
    "### Árbol de decisiones para la clasificación\n",
    "\n",
    "#### Árbol de clasificación\n",
    "Dado un conjunto de datos etiquetado, **un árbol de clasificación aprende una secuencia de preguntas sobre características individuales para inferir las etiquetas**. \n",
    "A diferencia de los modelos lineales, \n",
    "- los árboles pueden capturar relaciones no lineales entre características y etiquetas.\n",
    "- Además, los árboles **no requieren que las características estén en la misma escala mediante la estandarización**\n",
    "\n",
    "#### Conjunto de datos sobre cáncer de mama en 2D\n",
    "Para comprender los árboles de manera más concreta, intentaremos predecir si un tumor es maligno o benigno en el conjunto de datos de cáncer de mama de Wisconsin utilizando solo dos características. La figura aquí muestra un diagrama de dispersión de dos características de células cancerosas con tumores malignos en azul y tumores benignos en rojo.\n",
    "\n",
    "5. Diagrama de árbol de decisiones\n",
    "01:35 - 02:28\n",
    "Cuando se entrena un árbol de clasificación en este conjunto de datos, el árbol aprende una secuencia de preguntas if-else y cada pregunta involucra una característica y un punto de división. Eche un vistazo al diagrama de árbol aquí. En la parte superior, el árbol pregunta si la media de puntos cóncavos de una instancia es <= 0-punto-051. Si es así, la instancia atraviesa la rama Verdadera; de lo contrario, atraviesa la rama Falso. De manera similar, la instancia sigue atravesando las ramas internas hasta llegar al final. Luego se predice que la etiqueta de la instancia será la de la clase predominante en ese extremo. El número máximo de ramas que separan la parte superior de un extremo se conoce como profundidad máxima, que aquí es igual a 2.\n",
    "\n",
    "6. Árbol de clasificación en scikit-learn\n",
    "02:28 - 03:33\n",
    "Ahora que sabes qué es un árbol de clasificación, ajustemos uno con scikit-learn. Primero, importe DecisionTreeClassifier desde sklearn.tree como se muestra en la línea 1. Además, importe las funciones train_test_split() desde sklearn.model_selection y precision_score() desde sklearn.metrics. Para obtener una estimación imparcial del rendimiento de un modelo, debe evaluarlo en un conjunto de pruebas invisible. Para hacerlo, primero divida los datos en 80% de entrenamiento y 20% de prueba usando train_test_split(). Establezca el parámetro estratificar en y para que los conjuntos de entrenamiento y de prueba tengan la misma proporción de etiquetas de clase que el conjunto de datos no dividido. Ahora puede utilizar DecisionTreeClassifier() para crear una instancia de un clasificador de árbol, dt con una profundidad máxima de 2 estableciendo el parámetro max_ Depth en 2. Tenga en cuenta que el parámetro random_state se establece en 1 para mayor reproducibilidad.\n",
    "\n",
    "7. Árbol de clasificación en scikit-learn\n",
    "03:33 - 03:57\n",
    "Luego llame al método de ajuste en dt y pase X_train e y_train. Para predecir las etiquetas del conjunto de prueba, llame al método de predicción en dt. Finalmente imprima la precisión del conjunto de prueba usando precision_score(). Para comprender las predicciones del árbol de manera más concreta, veamos cómo clasifica las instancias en el espacio de características.\n",
    "\n",
    "8. Regiones de decisión\n",
    "03:57 - 04:24\n",
    "Un modelo de clasificación divide el espacio de características en regiones donde todas las instancias de una región se asignan a una sola etiqueta de clase. Estas regiones se conocen como regiones de decisión. Las regiones de decisión están separadas por superficies llamadas límites de decisión. La figura aquí muestra las regiones de decisión de un clasificador lineal. Observe cómo el límite es una línea recta.\n",
    "\n",
    "9. Regiones de decisión: CART versus modelo lineal\n",
    "04:24 - 04:40\n",
    "Por el contrario, como se muestra aquí a la derecha, un árbol de clasificación produce regiones de decisión rectangulares en el espacio de características. Esto sucede porque en cada división realizada por el árbol, solo interviene una característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9c8dc-f914-49d7-b2bd-4ea92e3c6cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
